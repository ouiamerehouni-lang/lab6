# lab6
**Etape 1: Préparer l’environnement Kubernetes**

On a mis en place un mini-cluster Kubernetes local et créé un espace isolé (churn-mlops) pour déployer notre système MLOps, prêt à accueillir les applications et services.

<img width="970" height="300" alt="image" src="https://github.com/user-attachments/assets/42ce06c6-aae0-4c11-9668-5f9e67b5c501" />
<img width="700" height="216" alt="image" src="https://github.com/user-attachments/assets/2c2a7e8e-b66a-45de-a1fc-bc5a4a2dd9c4" />
<img width="1245" height="127" alt="image" src="https://github.com/user-attachments/assets/f933ae8f-c009-4f40-ae31-729ea580c57b" />


**Étape 2 : Préparer l’image Docker de l’API churn**

On a préparé un environnement Python isolé avec la version 3.12 et installé toutes les dépendances nécessaires pour que l’API churn fonctionne correctement

<img width="612" height="55" alt="image" src="https://github.com/user-attachments/assets/06c4916d-aa03-4839-91bc-6c4477d4eac5" />
<img width="1064" height="154" alt="image" src="https://github.com/user-attachments/assets/575abc76-b913-4be0-b3d0-3bb25c6f9062" />
<img width="874" height="272" alt="image" src="https://github.com/user-attachments/assets/8e213dde-2d8f-401f-9e57-24bb9faa7146" />





